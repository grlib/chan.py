"""
Áº†ËÆ∫ÂàÜÊûêÊèêÁ§∫ËØçÁîüÊàêÂô® - Streamlit Version

ÂäüËÉΩÔºö
    - Â§öÁ∫ßÂà´ËÅîÁ´ãÂàÜÊûêÔºàÂë®Á∫ø„ÄÅÊó•Á∫ø„ÄÅ30ÂàÜÈíü„ÄÅ5ÂàÜÈíüÔºâ
    - ÂèØÈÖçÁΩÆÁöÑÊó∂Èó¥ËåÉÂõ¥
    - ÁîüÊàêÁªìÊûÑÂåñÁöÑÊèêÁ§∫ËØç‰ø°ÊÅØ‰æõÂ§ßÊ®°ÂûãÂàÜÊûê

‰ΩøÁî®ÊñπÊ≥ïÔºö
    streamlit run App/app.py
"""
import sys
from pathlib import Path

# Add project root to path for importing chan.py core modules
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from datetime import datetime, timedelta
import streamlit as st
from typing import Dict, Optional, List
import json
import os
import pandas as pd

from Chan import CChan
from ChanConfig import CChanConfig
from Common.CEnum import AUTYPE, KL_TYPE, DATA_SRC, BI_DIR
from App.config import get_data_source_for_chan


def get_chan_config() -> CChanConfig:
    """Ëé∑ÂèñÁº†ËÆ∫ÈÖçÁΩÆ"""
    return CChanConfig({
        "bi_strict": True,
        "zs_combine": True,
        "zs_algo": "normal",
        "seg_algo": "chan",
        "bs_type": "1,1p,2,2s,3a,3b",
        "macd_algo": "peak",
        "divergence_rate": float("inf"),
        "print_warning": False,
    })


def format_code(code: str) -> str:
    """
    Ê†ºÂºèÂåñËÇ°Á•®‰ª£Á†ÅÔºåÊ∑ªÂä†Â∏ÇÂú∫ÂâçÁºÄ
    
    Args:
        code: ËÇ°Á•®‰ª£Á†ÅÔºàÂ¶Ç '000001' Êàñ 'sh.600000'Ôºâ
    
    Returns:
        Ê†ºÂºèÂåñÂêéÁöÑ‰ª£Á†ÅÔºàÂ¶Ç 'sh.600000' Êàñ 'sz.000001'Ôºâ
    """
    if code.startswith(('sh.', 'sz.')):
        return code
    
    # Âà§Êñ≠Â∏ÇÂú∫Ôºö600/601/603/605/688ÂâçÁºÄÊòØ‰∏äÊµ∑Ôºå000/001/002/300ÂâçÁºÄÊòØÊ∑±Âú≥
    if code.startswith(('600', '601', '603', '605', '688')):
        return f"sh.{code}"
    else:
        return f"sz.{code}"


def analyze_multi_level(
    code: str,
    config: CChanConfig,
    time_ranges: Dict[KL_TYPE, Dict[str, str]]
) -> Dict[KL_TYPE, Optional[CChan]]:
    """
    Â§öÁ∫ßÂà´ËÅîÁ´ãÂàÜÊûê
    
    Args:
        code: ËÇ°Á•®‰ª£Á†Å
        config: Áº†ËÆ∫ÈÖçÁΩÆ
        time_ranges: Êó∂Èó¥ËåÉÂõ¥Â≠óÂÖ∏ÔºåÊ†ºÂºè‰∏∫ {KL_TYPE: {'begin': 'YYYY-MM-DD', 'end': 'YYYY-MM-DD'}}
    
    Returns:
        ÂàÜÊûêÁªìÊûúÂ≠óÂÖ∏ÔºåÊ†ºÂºè‰∏∫ {KL_TYPE: CChanÂØπË±°}
    """
    results = {}
    code_formatted = format_code(code)
    
    # ÊåâÁ∫ßÂà´‰ªéÂ§ßÂà∞Â∞èÂàÜÊûê
    level_order = [KL_TYPE.K_WEEK, KL_TYPE.K_DAY, KL_TYPE.K_30M, KL_TYPE.K_5M]
    
    for kl_type in level_order:
        if kl_type not in time_ranges:
            continue
            
        time_range = time_ranges[kl_type]
        begin_time = time_range.get('begin')
        end_time = time_range.get('end')
        
        if not begin_time:
            continue
            
        if not end_time:
            end_time = datetime.now().strftime("%Y-%m-%d")
        
        try:
            level_name_map = {
                KL_TYPE.K_WEEK: "Weekly",
                KL_TYPE.K_DAY: "Daily",
                KL_TYPE.K_30M: "30 Minutes",
                KL_TYPE.K_5M: "5 Minutes",
            }
            level_name = level_name_map.get(kl_type, kl_type.name)
            with st.spinner(f"Analyzing {level_name}..."):
                data_src = get_data_source_for_chan()
                chan = CChan(
                    code=code_formatted,
                    begin_time=begin_time,
                    end_time=end_time,
                    data_src=data_src,
                    lv_list=[kl_type],
                    config=config,
                    autype=AUTYPE.QFQ,
                )
                results[kl_type] = chan
        except Exception as e:
            level_name_map = {
                KL_TYPE.K_WEEK: "Weekly",
                KL_TYPE.K_DAY: "Daily",
                KL_TYPE.K_30M: "30 Minutes",
                KL_TYPE.K_5M: "5 Minutes",
            }
            level_name = level_name_map.get(kl_type, kl_type.name)
            st.error(f"Failed to analyze {level_name}: {e}")
            results[kl_type] = None
    
    return results


def extract_bi_info(chan: CChan, kl_type: KL_TYPE, config: CChanConfig) -> List[Dict]:
    """ÊèêÂèñÁ¨î‰ø°ÊÅØÔºåÂåÖÂê´MACD‰ø°ÊÅØ"""
    if chan is None or kl_type not in chan.kl_datas:
        return []
    
    bi_list = chan[kl_type].bi_list
    bi_info = []
    macd_algo = config.bs_point_conf.b_conf.macd_algo
    
    for bi in bi_list:
        # Ëé∑ÂèñMACDÊåáÊ†á
        macd_metric = None
        try:
            macd_metric = bi.cal_macd_metric(macd_algo, is_reverse=False)
        except:
            pass
        
        # Ëé∑ÂèñÁ¨îÁöÑMACDÂÄºÔºàÂ¶ÇÊûúÊúâÔºâ
        begin_macd = None
        end_macd = None
        try:
            begin_klu = bi.get_begin_klu()
            end_klu = bi.get_end_klu()
            if hasattr(begin_klu, 'macd') and begin_klu.macd:
                begin_macd = {
                    "DIF": begin_klu.macd.DIF,
                    "DEA": begin_klu.macd.DEA,
                    "MACD": begin_klu.macd.macd
                }
            if hasattr(end_klu, 'macd') and end_klu.macd:
                end_macd = {
                    "DIF": end_klu.macd.DIF,
                    "DEA": end_klu.macd.DEA,
                    "MACD": end_klu.macd.macd
                }
        except:
            pass
        
        bi_info.append({
            "idx": bi.idx,
            "dir": "Âêë‰∏ä" if bi.dir == BI_DIR.UP else "Âêë‰∏ã",
            "begin_price": bi.get_begin_val(),
            "end_price": bi.get_end_val(),
            "begin_time": bi.get_begin_klu().time.to_str(),
            "end_time": bi.get_end_klu().time.to_str(),
            "is_sure": bi.is_sure,
            "macd_metric": macd_metric,
            "begin_macd": begin_macd,
            "end_macd": end_macd,
        })
    
    return bi_info


def extract_seg_info(chan: CChan, kl_type: KL_TYPE, config: CChanConfig) -> List[Dict]:
    """ÊèêÂèñÁ∫øÊÆµ‰ø°ÊÅØÔºåÂåÖÂê´MACD‰ø°ÊÅØ"""
    if chan is None or kl_type not in chan.kl_datas:
        return []
    
    seg_list = chan[kl_type].seg_list
    seg_info = []
    macd_algo = config.seg_bs_point_conf.b_conf.macd_algo
    
    for seg in seg_list:
        # Ëé∑ÂèñÁ∫øÊÆµMACDÊåáÊ†á
        macd_metric = None
        try:
            macd_metric = seg.cal_macd_metric(macd_algo, is_reverse=False)
        except:
            pass
        
        seg_info.append({
            "idx": seg.idx,
            "dir": "Âêë‰∏ä" if seg.dir == BI_DIR.UP else "Âêë‰∏ã",
            "begin_price": seg.get_begin_val(),
            "end_price": seg.get_end_val(),
            "begin_time": seg.start_bi.get_begin_klu().time.to_str(),
            "end_time": seg.end_bi.get_end_klu().time.to_str(),
            "is_sure": seg.is_sure,
            "macd_metric": macd_metric,
        })
    
    return seg_info


def extract_zs_info(chan: CChan, kl_type: KL_TYPE, config: CChanConfig) -> List[Dict]:
    """ÊèêÂèñ‰∏≠Êû¢‰ø°ÊÅØÔºåÂåÖÂê´ËÉåÈ©∞‰ø°ÊÅØ"""
    if chan is None or kl_type not in chan.kl_datas:
        return []
    
    zs_list = chan[kl_type].zs_list
    zs_info = []
    bsp_config = config.bs_point_conf.b_conf
    
    for idx, zs in enumerate(zs_list):
        # Ê£ÄÊü•ËÉåÈ©∞
        is_divergence = False
        divergence_rate = None
        bi_in_macd = None
        bi_out_macd = None
        
        try:
            if zs.bi_in and zs.bi_out:
                # Ëé∑ÂèñËøõÂÖ•ÂíåÁ¶ªÂºÄ‰∏≠Êû¢ÁöÑÁ¨îÁöÑMACDÊåáÊ†á
                bi_in_macd = zs.get_bi_in().cal_macd_metric(bsp_config.macd_algo, is_reverse=False)
                bi_out_macd = zs.get_bi_out().cal_macd_metric(bsp_config.macd_algo, is_reverse=True)
                
                # Ê£ÄÊü•ÊòØÂê¶ËÉåÈ©∞
                if zs.end_bi_break():
                    is_divergence, divergence_rate = zs.is_divergence(bsp_config)
        except:
            pass
        
        zs_info.append({
            "idx": idx + 1,  # Use list index + 1 as identifier
            "begin_bi_idx": zs.begin_bi.idx,
            "end_bi_idx": zs.end_bi.idx,
            "begin_time": zs.begin.time.to_str(),
            "end_time": zs.end.time.to_str(),
            "high": zs.high,
            "low": zs.low,
            "is_sure": zs.is_sure,
            "is_divergence": is_divergence,
            "divergence_rate": divergence_rate,
            "bi_in_macd": bi_in_macd,
            "bi_out_macd": bi_out_macd,
        })
    
    return zs_info


def extract_macd_info(chan: CChan, kl_type: KL_TYPE) -> List[Dict]:
    """ÊèêÂèñKÁ∫øMACD‰ø°ÊÅØ"""
    if chan is None or kl_type not in chan.kl_datas:
        return []
    
    kl_data = chan[kl_type]
    macd_info = []
    
    # Ëé∑ÂèñÊúÄËøëÁöÑ‰∏Ä‰∫õKÁ∫øÁöÑMACD‰ø°ÊÅØ
    klu_list = []
    for klc in kl_data.lst:
        klu_list.extend(klc.lst)
    
    # Âè™ÂèñÊúÄËøë50Ê†πKÁ∫øÁöÑMACD‰ø°ÊÅØ
    recent_klu = klu_list[-50:] if len(klu_list) > 50 else klu_list
    
    for klu in recent_klu:
        if hasattr(klu, 'macd') and klu.macd:
            macd_info.append({
                "time": klu.time.to_str(),
                "close": klu.close,
                "DIF": klu.macd.DIF,
                "DEA": klu.macd.DEA,
                "MACD": klu.macd.macd,
            })
    
    return macd_info


def generate_prompt_text(
    code: str,
    code_name: str,
    analysis_results: Dict[KL_TYPE, Optional[CChan]],
    time_ranges: Dict[KL_TYPE, Dict[str, str]],
    config: CChanConfig
) -> str:
    """
    ÁîüÊàêÁº†ËÆ∫ÂàÜÊûêÊèêÁ§∫ËØçÊñáÊú¨
    
    Args:
        code: ËÇ°Á•®‰ª£Á†Å
        code_name: ËÇ°Á•®ÂêçÁß∞
        analysis_results: ÂàÜÊûêÁªìÊûúÂ≠óÂÖ∏
        time_ranges: Êó∂Èó¥ËåÉÂõ¥Â≠óÂÖ∏
    
    Returns:
        Ê†ºÂºèÂåñÁöÑÊèêÁ§∫ËØçÊñáÊú¨
    """
    level_names = {
        KL_TYPE.K_WEEK: "Âë®Á∫ø",
        KL_TYPE.K_DAY: "Êó•Á∫ø",
        KL_TYPE.K_30M: "30ÂàÜÈíü",
        KL_TYPE.K_5M: "5ÂàÜÈíü",
    }
    
    prompt_parts = []
    prompt_parts.append(f"# Áº†ËÆ∫Â§öÁ∫ßÂà´ËÅîÁ´ãÂàÜÊûê - {code_name} ({code})\n")
    prompt_parts.append(f"ÂàÜÊûêÊó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    prompt_parts.append("=" * 80 + "\n\n")
    
    # ÊåâÁ∫ßÂà´‰ªéÂ§ßÂà∞Â∞èËæìÂá∫
    level_order = [KL_TYPE.K_WEEK, KL_TYPE.K_DAY, KL_TYPE.K_30M, KL_TYPE.K_5M]
    
    for kl_type in level_order:
        if kl_type not in analysis_results:
            continue
        
        chan = analysis_results[kl_type]
        if chan is None:
            continue
        
        level_name = level_names[kl_type]
        time_range = time_ranges.get(kl_type, {})
        
        prompt_parts.append(f"## {level_name}Á∫ßÂà´ÂàÜÊûê\n")
        prompt_parts.append(f"ÂàÜÊûêÊó∂Èó¥ËåÉÂõ¥: {time_range.get('begin', 'N/A')} Ëá≥ {time_range.get('end', 'N/A')}\n")
        prompt_parts.append("-" * 80 + "\n")
        
        # KÁ∫øÊï∞ÊçÆÁªüËÆ°
        if kl_type in chan.kl_datas:
            kl_data = chan[kl_type]
            kline_count = sum(len(klc.lst) for klc in kl_data.lst)
            prompt_parts.append(f"KÁ∫øÊï∞Èáè: {kline_count}\n")
            
            if kl_data.lst:
                first_kl = kl_data.lst[0].lst[0]
                last_kl = kl_data.lst[-1].lst[-1]
                prompt_parts.append(f"Ëµ∑ÂßãÊó∂Èó¥: {first_kl.time.to_str()}, ‰ª∑Ê†º: {first_kl.close:.2f}\n")
                prompt_parts.append(f"ÁªìÊùüÊó∂Èó¥: {last_kl.time.to_str()}, ‰ª∑Ê†º: {last_kl.close:.2f}\n")
                price_change = ((last_kl.close - first_kl.close) / first_kl.close) * 100
                prompt_parts.append(f"ÊúüÈó¥Ê∂®Ë∑åÂπÖ: {price_change:.2f}%\n")
        
        prompt_parts.append("\n")
        
        # Á¨î‰ø°ÊÅØÔºàÂåÖÂê´MACDÔºâ
        bi_info = extract_bi_info(chan, kl_type, config)
        prompt_parts.append(f"### Á¨îÔºàBiÔºâÂàÜÊûê\n")
        prompt_parts.append(f"Á¨îÊï∞Èáè: {len(bi_info)}\n")
        if bi_info:
            prompt_parts.append("ÊúÄËøë5Á¨îÔºàÂê´MACD‰ø°ÊÅØÔºâ:\n")
            for bi in bi_info[-5:]:
                macd_str = ""
                if bi['macd_metric'] is not None:
                    macd_str = f" | MACDÊåáÊ†á: {bi['macd_metric']:.4f}"
                if bi['begin_macd'] and bi['end_macd']:
                    macd_str += f" | Ëµ∑ÂßãMACD(DIF/DEA/MACD): {bi['begin_macd']['DIF']:.4f}/{bi['begin_macd']['DEA']:.4f}/{bi['begin_macd']['MACD']:.4f}"
                    macd_str += f" | ÁªìÊùüMACD(DIF/DEA/MACD): {bi['end_macd']['DIF']:.4f}/{bi['end_macd']['DEA']:.4f}/{bi['end_macd']['MACD']:.4f}"
                
                prompt_parts.append(
                    f"  Á¨î{bi['idx']}: {bi['dir']} | "
                    f"Êó∂Èó¥: {bi['begin_time']} ~ {bi['end_time']} | "
                    f"‰ª∑Ê†º: {bi['begin_price']:.2f} ~ {bi['end_price']:.2f} | "
                    f"Á°ÆËÆ§: {'ÊòØ' if bi['is_sure'] else 'Âê¶'}{macd_str}\n"
                )
        prompt_parts.append("\n")
        
        # Á∫øÊÆµ‰ø°ÊÅØÔºàÂåÖÂê´MACDÔºâ
        seg_info = extract_seg_info(chan, kl_type, config)
        prompt_parts.append(f"### Á∫øÊÆµÔºàSegmentÔºâÂàÜÊûê\n")
        prompt_parts.append(f"Á∫øÊÆµÊï∞Èáè: {len(seg_info)}\n")
        if seg_info:
            prompt_parts.append("ÊúÄËøë3Êù°Á∫øÊÆµÔºàÂê´MACD‰ø°ÊÅØÔºâ:\n")
            for seg in seg_info[-3:]:
                macd_str = ""
                if seg['macd_metric'] is not None:
                    macd_str = f" | MACDÊåáÊ†á: {seg['macd_metric']:.4f}"
                
                prompt_parts.append(
                    f"  Á∫øÊÆµ{seg['idx']}: {seg['dir']} | "
                    f"Êó∂Èó¥: {seg['begin_time']} ~ {seg['end_time']} | "
                    f"‰ª∑Ê†º: {seg['begin_price']:.2f} ~ {seg['end_price']:.2f} | "
                    f"Á°ÆËÆ§: {'ÊòØ' if seg['is_sure'] else 'Âê¶'}{macd_str}\n"
                )
        prompt_parts.append("\n")
        
        # ‰∏≠Êû¢‰ø°ÊÅØÔºàÂåÖÂê´ËÉåÈ©∞Ôºâ
        zs_info = extract_zs_info(chan, kl_type, config)
        prompt_parts.append(f"### ‰∏≠Êû¢ÔºàZhongshuÔºâÂàÜÊûê\n")
        prompt_parts.append(f"‰∏≠Êû¢Êï∞Èáè: {len(zs_info)}\n")
        if zs_info:
            prompt_parts.append("ÊúÄËøë3‰∏™‰∏≠Êû¢ÔºàÂê´ËÉåÈ©∞‰ø°ÊÅØÔºâ:\n")
            for zs in zs_info[-3:]:
                divergence_str = ""
                if zs['is_divergence'] is not None:
                    if zs['is_divergence']:
                        divergence_str = f" | ËÉåÈ©∞: ÊòØ | ËÉåÈ©∞Áéá: {zs['divergence_rate']:.4f}" if zs['divergence_rate'] else " | ËÉåÈ©∞: ÊòØ"
                    else:
                        divergence_str = f" | ËÉåÈ©∞: Âê¶ | ËÉåÈ©∞Áéá: {zs['divergence_rate']:.4f}" if zs['divergence_rate'] else " | ËÉåÈ©∞: Âê¶"
                
                macd_str = ""
                if zs['bi_in_macd'] is not None and zs['bi_out_macd'] is not None:
                    macd_str = f" | ËøõÂÖ•Á¨îMACD: {zs['bi_in_macd']:.4f} | Á¶ªÂºÄÁ¨îMACD: {zs['bi_out_macd']:.4f}"
                
                prompt_parts.append(
                    f"  ‰∏≠Êû¢{zs['idx']} (Á¨î{zs['begin_bi_idx']}-{zs['end_bi_idx']}): "
                    f"Êó∂Èó¥: {zs['begin_time']} ~ {zs['end_time']} | "
                    f"Âå∫Èó¥: {zs['low']:.2f} ~ {zs['high']:.2f} | "
                    f"Á°ÆËÆ§: {'ÊòØ' if zs['is_sure'] else 'Âê¶'}{divergence_str}{macd_str}\n"
                )
        prompt_parts.append("\n")
        
        # MACD‰ø°ÊÅØ
        macd_info = extract_macd_info(chan, kl_type)
        prompt_parts.append(f"### MACDÊåáÊ†áÂàÜÊûê\n")
        if macd_info:
            prompt_parts.append(f"ÊúÄËøëMACDÊï∞ÊçÆÔºàÊúÄËøë{len(macd_info)}Ê†πKÁ∫øÔºâ:\n")
            prompt_parts.append("ÊúÄËøë10Ê†πKÁ∫øÁöÑMACD:\n")
            for macd in macd_info[-10:]:
                prompt_parts.append(
                    f"  Êó∂Èó¥: {macd['time']} | Êî∂Áõò: {macd['close']:.2f} | "
                    f"DIF: {macd['DIF']:.4f} | DEA: {macd['DEA']:.4f} | MACD: {macd['MACD']:.4f}\n"
                )
        prompt_parts.append("\n")
        
        prompt_parts.append("=" * 80 + "\n\n")
    
    # Â§öÁ∫ßÂà´ËÅîÁ´ãÂàÜÊûêÊÄªÁªìÂíåÊú™Êù•Ëµ∞ÂäøÂÆåÂÖ®ÂàÜÁ±ª
    prompt_parts.append("## Â§öÁ∫ßÂà´ËÅîÁ´ãÂàÜÊûêÊÄªÁªì‰∏éÊú™Êù•Ëµ∞ÂäøÂÆåÂÖ®ÂàÜÁ±ª\n")
    prompt_parts.append("ËØ∑Âü∫‰∫é‰ª•‰∏äÂ§öÁ∫ßÂà´ÂàÜÊûêÁªìÊûúÔºåËøõË°å‰ª•‰∏ãÂàÜÊûêÔºö\n\n")
    
    prompt_parts.append("### ‰∏Ä„ÄÅÂΩìÂâçË∂ãÂäøÂà§Êñ≠\n")
    prompt_parts.append("1. ÁªìÂêàÂë®Á∫ø„ÄÅÊó•Á∫ø„ÄÅ30ÂàÜÈíü„ÄÅ5ÂàÜÈíüÁöÑË∂ãÂäøÊñπÂêëÔºåÂà§Êñ≠ÂΩìÂâçÂ§Ñ‰∫é‰ªÄ‰πàË∂ãÂäø‰∏≠\n")
    prompt_parts.append("2. ËØÜÂà´ÂêÑÁ∫ßÂà´ÁöÑÂÖ≥ÈîÆÊîØÊíë‰ΩçÂíåÈòªÂäõ‰Ωç\n")
    prompt_parts.append("3. ÂàÜÊûêÂΩìÂâç‰ª∑Ê†ºÂú®ÂêÑÁ∫ßÂà´‰∏≠ÁöÑ‰ΩçÁΩÆÔºàÊòØÂê¶Êé•ËøëÂÖ≥ÈîÆ‰ΩçÁΩÆÔºâ\n\n")
    
    prompt_parts.append("### ‰∫å„ÄÅMACDÂíåËÉåÈ©∞ÂàÜÊûê\n")
    prompt_parts.append("1. ÂàÜÊûêÂêÑÁ∫ßÂà´Á¨îÂíåÁ∫øÊÆµÁöÑMACDÊåáÊ†áÂèòÂåñË∂ãÂäø\n")
    prompt_parts.append("2. ËØÜÂà´ÂêÑÁ∫ßÂà´‰∏≠Êû¢ÁöÑËÉåÈ©∞ÊÉÖÂÜµÔºàÊòØÂê¶Âá∫Áé∞ËÉåÈ©∞ÔºåËÉåÈ©∞Á®ãÂ∫¶Â¶Ç‰ΩïÔºâ\n")
    prompt_parts.append("3. ÂàÜÊûêMACD‰∏é‰ª∑Ê†ºËµ∞ÂäøÁöÑËÉåÁ¶ªÊÉÖÂÜµ\n")
    prompt_parts.append("4. Âà§Êñ≠ÂΩìÂâçÊòØÂê¶Â§Ñ‰∫éËÉåÈ©∞Áä∂ÊÄÅÔºå‰ª•ÂèäËÉåÈ©∞ÁöÑÁ∫ßÂà´\n\n")
    
    prompt_parts.append("### ‰∏â„ÄÅÊú™Êù•Ëµ∞ÂäøÂÆåÂÖ®ÂàÜÁ±ª\n")
    prompt_parts.append("Ê†πÊçÆÁº†ËÆ∫ÁêÜËÆ∫ÔºåËØ∑ÂØπÊú™Êù•ÁöÑËµ∞ÂäøËøõË°åÂÆåÂÖ®ÂàÜÁ±ªÂàÜÊûêÔºåÂåÖÊã¨Ôºö\n\n")
    prompt_parts.append("**1. Âë®Á∫øÁ∫ßÂà´Êú™Êù•Ëµ∞ÂäøÂàÜÁ±ªÔºö**\n")
    prompt_parts.append("   - ‰∏äÊ∂®ÊÉÖÂÜµÔºöÁªßÁª≠‰∏äÊ∂®„ÄÅÂΩ¢ÊàêÊñ∞ÁöÑ‰∏≠Êû¢„ÄÅÂΩ¢ÊàêËÉåÈ©∞ÂêéÂõûË∞É\n")
    prompt_parts.append("   - ‰∏ãË∑åÊÉÖÂÜµÔºöÁªßÁª≠‰∏ãË∑å„ÄÅÂΩ¢ÊàêÊñ∞ÁöÑ‰∏≠Êû¢„ÄÅÂΩ¢ÊàêËÉåÈ©∞ÂêéÂèçÂºπ\n")
    prompt_parts.append("   - ÁõòÊï¥ÊÉÖÂÜµÔºöÂú®‰∏≠Êû¢ÂÜÖÈúáËç°„ÄÅÁ™ÅÁ†¥‰∏≠Êû¢Âêë‰∏ä„ÄÅË∑åÁ†¥‰∏≠Êû¢Âêë‰∏ã\n\n")
    
    prompt_parts.append("**2. Êó•Á∫øÁ∫ßÂà´Êú™Êù•Ëµ∞ÂäøÂàÜÁ±ªÔºö**\n")
    prompt_parts.append("   - ÁªìÂêàÂë®Á∫øË∂ãÂäøÔºåÂàÜÊûêÊó•Á∫øÂèØËÉΩÁöÑËµ∞ÂäøÂèòÂåñ\n")
    prompt_parts.append("   - ËØÜÂà´Êó•Á∫øÁ∫ßÂà´ÁöÑÂÖ≥ÈîÆ‰ΩçÁΩÆÂíåÂèØËÉΩÁöÑËΩ¨ÊäòÁÇπ\n")
    prompt_parts.append("   - ÂàÜÊûêÊó•Á∫øMACDÂíåËÉåÈ©∞ÊÉÖÂÜµÂØπÊú™Êù•Ëµ∞ÂäøÁöÑÂΩ±Âìç\n\n")
    
    prompt_parts.append("**3. 30ÂàÜÈíüÁ∫ßÂà´Êú™Êù•Ëµ∞ÂäøÂàÜÁ±ªÔºö**\n")
    prompt_parts.append("   - ÁªìÂêàÊó•Á∫øË∂ãÂäøÔºåÂàÜÊûê30ÂàÜÈíüÂèØËÉΩÁöÑËµ∞ÂäøÂèòÂåñ\n")
    prompt_parts.append("   - ËØÜÂà´30ÂàÜÈíüÁ∫ßÂà´ÁöÑÂÖ≥ÈîÆ‰ΩçÁΩÆÂíåÂèØËÉΩÁöÑËΩ¨ÊäòÁÇπ\n")
    prompt_parts.append("   - ÂàÜÊûê30ÂàÜÈíüMACDÂíåËÉåÈ©∞ÊÉÖÂÜµÂØπÊú™Êù•Ëµ∞ÂäøÁöÑÂΩ±Âìç\n\n")
    
    prompt_parts.append("**4. 5ÂàÜÈíüÁ∫ßÂà´Êú™Êù•Ëµ∞ÂäøÂàÜÁ±ªÔºö**\n")
    prompt_parts.append("   - ÁªìÂêà30ÂàÜÈíüË∂ãÂäøÔºåÂàÜÊûê5ÂàÜÈíüÂèØËÉΩÁöÑËµ∞ÂäøÂèòÂåñ\n")
    prompt_parts.append("   - ËØÜÂà´5ÂàÜÈíüÁ∫ßÂà´ÁöÑÂÖ≥ÈîÆ‰ΩçÁΩÆÂíåÂèØËÉΩÁöÑËΩ¨ÊäòÁÇπ\n")
    prompt_parts.append("   - ÂàÜÊûê5ÂàÜÈíüMACDÂíåËÉåÈ©∞ÊÉÖÂÜµÂØπÊú™Êù•Ëµ∞ÂäøÁöÑÂΩ±Âìç\n\n")
    
    prompt_parts.append("**5. Â§öÁ∫ßÂà´ËÅîÁ´ãÂàÜÊûêÔºö**\n")
    prompt_parts.append("   - ÁªºÂêàÂàÜÊûêÂêÑÁ∫ßÂà´Ëµ∞ÂäøÁöÑÁõ∏‰∫íÂΩ±Âìç\n")
    prompt_parts.append("   - ËØÜÂà´Â§öÁ∫ßÂà´ÂÖ±ÊåØÁöÑÂÖ≥ÈîÆ‰ΩçÁΩÆ\n")
    prompt_parts.append("   - Âà§Êñ≠Êú™Êù•ÊúÄÂèØËÉΩÁöÑËµ∞ÂäøË∑ØÂæÑÔºàÊåâÊ¶ÇÁéáÊéíÂ∫èÔºâ\n")
    prompt_parts.append("   - ÂàÜÊûêÂêÑÁßçËµ∞ÂäøÂàÜÁ±ªÁöÑÊ¶ÇÁéáÂíåÊù°‰ª∂\n\n")
    
    prompt_parts.append("### Âõõ„ÄÅÊìç‰ΩúÂª∫ËÆÆ\n")
    prompt_parts.append("1. Ê†πÊçÆÊú™Êù•Ëµ∞ÂäøÂÆåÂÖ®ÂàÜÁ±ªÔºåÁªôÂá∫‰∏çÂêåÊÉÖÂÜµ‰∏ãÁöÑÊìç‰ΩúÁ≠ñÁï•\n")
    prompt_parts.append("2. ËØÜÂà´ÊΩúÂú®ÁöÑÈ£éÈô©‰ø°Âè∑ÂíåÈúÄË¶ÅÊ≥®ÊÑèÁöÑÂÖ≥ÈîÆ‰ΩçÁΩÆ\n")
    prompt_parts.append("3. ÁªôÂá∫ÂÖ∑‰ΩìÁöÑÊìç‰ΩúÂª∫ËÆÆÔºö‰π∞ÂÖ•Êó∂Êú∫„ÄÅÂçñÂá∫Êó∂Êú∫„ÄÅÊ≠¢Êçü‰ΩçÁΩÆ„ÄÅÁõÆÊ†á‰ΩçÁΩÆ\n")
    prompt_parts.append("4. ËØ¥ÊòéÂêÑÁßçËµ∞ÂäøÂàÜÁ±ª‰∏ãÁöÑÂ∫îÂØπÁ≠ñÁï•\n\n")
    
    prompt_parts.append("### ‰∫î„ÄÅÈ£éÈô©ÊèêÁ§∫\n")
    prompt_parts.append("1. ËØÜÂà´ÊΩúÂú®ÁöÑÈ£éÈô©‰ø°Âè∑\n")
    prompt_parts.append("2. ËØ¥ÊòéÈúÄË¶ÅÊ≥®ÊÑèÁöÑÂÖ≥ÈîÆ‰ΩçÁΩÆÂíåÂÖ≥ÈîÆ‰∫ã‰ª∂\n")
    prompt_parts.append("3. ÊèêÈÜíÂèØËÉΩÂá∫Áé∞ÁöÑÊÑèÂ§ñÊÉÖÂÜµ\n")
    
    return "".join(prompt_parts)


def load_favorites():
    """Load favorites data from favorites.csv"""
    data_dir = Path(__file__).resolve().parent.parent.parent / "data"
    favorites_file = data_dir / "favorites.csv"
    if favorites_file.exists():
        return pd.read_csv(favorites_file)
    else:
        return pd.DataFrame(columns=["code", "name", "added_date", "note"])


def get_stock_name(code: str, favorites: pd.DataFrame = None) -> str:
    """Get stock name from favorites or return code"""
    if favorites is None:
        favorites = load_favorites()
    
    if not favorites.empty:
        matched = favorites[favorites["code"] == code]
        if not matched.empty:
            return matched.iloc[0]["name"]
    
    return code


def main():
    st.set_page_config(
        page_title="Chan Theory Analysis Prompt Generator",
        page_icon="üìä",
        layout="wide"
    )
    
    st.title("üìä Chan Theory Multi-Level Analysis Prompt Generator")
    st.markdown("---")
    
    # Load favorites
    favorites = load_favorites()
    
    # Stock code input - allow selection from favorites or manual input
    col1, col2 = st.columns([2, 1])
    with col1:
        stock_code = ""
        if not favorites.empty:
            # Create options for selectbox
            stock_options = [f"{row['code']} - {row['name']}" for _, row in favorites.iterrows()]
            selected_option = st.selectbox(
                "Select Stock from Favorites",
                options=[""] + stock_options,
                index=0,
                key="favorite_stock_selector"
            )
            
            if selected_option and selected_option != "":
                # Extract code from selected option
                stock_code = selected_option.split(" - ")[0]
            
            # Always show manual input as fallback
            manual_code = st.text_input(
                "Or Enter Stock Code Manually",
                value=stock_code if stock_code else "",
                help="Enter stock code, e.g., 000001, 600000",
                key="manual_stock_code"
            )
            # Use manual input if provided, otherwise use selected favorite
            stock_code = manual_code if manual_code else stock_code
        else:
            stock_code = st.text_input(
                "Stock Code",
                value="000001",
                help="Enter stock code, e.g., 000001, 600000"
            )
    
    with col2:
        if not favorites.empty:
            st.info(f"üìã {len(favorites)} stocks in favorites")
        else:
            st.info("üí° Add stocks to favorites in the Favorites page")
    
    # Time range configuration
    st.subheader("‚è∞ Analysis Time Range Configuration")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("**Weekly**")
        week_years = st.number_input("Years", min_value=1, max_value=10, value=3, key="week_years")
        week_end = st.date_input("End Date", value=datetime.now().date(), key="week_end")
    
    with col2:
        st.markdown("**Daily**")
        day_years = st.number_input("Years", min_value=1, max_value=10, value=1, key="day_years")
        day_end = st.date_input("End Date", value=datetime.now().date(), key="day_end")
    
    with col3:
        st.markdown("**30 Minutes**")
        min30_months = st.number_input("Months", min_value=1, max_value=12, value=3, key="min30_months")
        min30_end = st.date_input("End Date", value=datetime.now().date(), key="min30_end")
    
    with col4:
        st.markdown("**5 Minutes**")
        min5_days = st.number_input("Days", min_value=1, max_value=30, value=10, key="min5_days")
        min5_end = st.date_input("End Date", value=datetime.now().date(), key="min5_end")
    
    # ËÆ°ÁÆóÂºÄÂßãÊó∂Èó¥
    week_begin = (week_end - timedelta(days=week_years * 365)).strftime("%Y-%m-%d")
    day_begin = (day_end - timedelta(days=day_years * 365)).strftime("%Y-%m-%d")
    min30_begin = (min30_end - timedelta(days=min30_months * 30)).strftime("%Y-%m-%d")
    min5_begin = (min5_end - timedelta(days=min5_days)).strftime("%Y-%m-%d")
    
    time_ranges = {
        KL_TYPE.K_WEEK: {
            'begin': week_begin,
            'end': week_end.strftime("%Y-%m-%d")
        },
        KL_TYPE.K_DAY: {
            'begin': day_begin,
            'end': day_end.strftime("%Y-%m-%d")
        },
        KL_TYPE.K_30M: {
            'begin': min30_begin,
            'end': min30_end.strftime("%Y-%m-%d")
        },
        KL_TYPE.K_5M: {
            'begin': min5_begin,
            'end': min5_end.strftime("%Y-%m-%d")
        },
    }
    
    # Analysis button
    if st.button("üöÄ Start Analysis", type="primary", use_container_width=True):
        if not stock_code:
            st.error("Please enter a stock code")
            return
        
        config = get_chan_config()
        code_formatted = format_code(stock_code)
        code_name = get_stock_name(stock_code, favorites)
        
        # Execute multi-level analysis
        analysis_results = analyze_multi_level(code_formatted, config, time_ranges)
        
        # Check if there are successful analysis results
        success_count = sum(1 for v in analysis_results.values() if v is not None)
        if success_count == 0:
            st.error("All level analyses failed. Please check the stock code and time range.")
            return
        
        st.success(f"Successfully analyzed {success_count} level(s)")
        
        # Generate prompt text
        prompt_text = generate_prompt_text(
            code_formatted,
            code_name,
            analysis_results,
            time_ranges,
            config
        )
        
        # Display prompt text
        st.subheader("üìù Generated Prompt")
        st.text_area(
            "Prompt Content",
            value=prompt_text,
            height=600,
            label_visibility="collapsed"
        )
        
        # Download button
        st.download_button(
            label="üì• Download Prompt File",
            data=prompt_text,
            file_name=f"chan_analysis_{stock_code}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain"
        )
        
        # Display summary statistics
        with st.expander("üìä Analysis Results Summary", expanded=False):
            for kl_type, chan in analysis_results.items():
                if chan is None:
                    continue
                
                level_names = {
                    KL_TYPE.K_WEEK: "Weekly",
                    KL_TYPE.K_DAY: "Daily",
                    KL_TYPE.K_30M: "30 Minutes",
                    KL_TYPE.K_5M: "5 Minutes",
                }
                
                level_name = level_names[kl_type]
                if kl_type in chan.kl_datas:
                    kl_data = chan[kl_type]
                    st.markdown(f"**{level_name}**:")
                    st.markdown(f"- K-lines: {sum(len(klc.lst) for klc in kl_data.lst)}")
                    st.markdown(f"- Bi: {len(kl_data.bi_list)}")
                    st.markdown(f"- Segments: {len(kl_data.seg_list)}")
                    st.markdown(f"- Zhongshu: {len(kl_data.zs_list)}")
                    
                    # Count divergences
                    divergence_count = 0
                    try:
                        bsp_config = config.bs_point_conf.b_conf
                        for zs in kl_data.zs_list:
                            if zs.bi_in and zs.bi_out and zs.end_bi_break():
                                is_div, _ = zs.is_divergence(bsp_config)
                                if is_div:
                                    divergence_count += 1
                    except Exception as e:
                        pass
                    st.markdown(f"- Divergences: {divergence_count}")


if __name__ == "__main__":
    main()
